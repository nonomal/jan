"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6770],{31010:(e,d,n)=>{n.r(d),n.d(d,{assets:()=>c,contentTitle:()=>i,default:()=>a,frontMatter:()=>t,metadata:()=>l,toc:()=>h});var s=n(85893),r=n(11151);const t={title:"Pre-configured Models",sidebar_position:3},i=void 0,l={id:"guides/models-list",title:"Pre-configured Models",description:"Overview",source:"@site/docs/guides/models-list.mdx",sourceDirName:"guides",slug:"/guides/models-list",permalink:"/guides/models-list",draft:!1,unlisted:!1,editUrl:"https://github.com/janhq/jan/tree/dev/docs/docs/guides/models-list.mdx",tags:[],version:"current",lastUpdatedBy:"Henry",lastUpdatedAt:1710497836,formattedLastUpdatedAt:"Mar 15, 2024",sidebarPosition:3,frontMatter:{title:"Pre-configured Models",sidebar_position:3},sidebar:"guidesSidebar",previous:{title:"Local Server",permalink:"/guides/start-server"},next:{title:"Best Practices",permalink:"/guides/best-practices"}},c={},h=[{value:"Overview",id:"overview",level:2},{value:"Model details",id:"model-details",level:2}];function o(e){const d={a:"a",admonition:"admonition",code:"code",h2:"h2",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(d.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(d.p,{children:"Jan provides various pre-configured AI models with different capabilities. Please see the following list for details."}),"\n",(0,s.jsxs)(d.table,{children:[(0,s.jsx)(d.thead,{children:(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.th,{children:"Model"}),(0,s.jsx)(d.th,{children:"Description"})]})}),(0,s.jsxs)(d.tbody,{children:[(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Mistral Instruct 7B Q4"}),(0,s.jsx)(d.td,{children:"A model designed for a comprehensive understanding through training on extensive internet data"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenHermes Neural 7B Q4"}),(0,s.jsx)(d.td,{children:"A merged model using the TIES method. It performs well in various benchmarks"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Stealth 7B Q4"}),(0,s.jsx)(d.td,{children:"This is a new experimental family designed to enhance Mathematical and Logical abilities"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Trinity-v1.2 7B Q4"}),(0,s.jsx)(d.td,{children:"An experimental model merge using the Slerp method"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Openchat-3.5 7B Q4"}),(0,s.jsx)(d.td,{children:"An open-source model that has a performance that surpasses that of ChatGPT-3.5 and Grok-1 across various benchmarks"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Wizard Coder Python 13B Q5"}),(0,s.jsx)(d.td,{children:"A Python coding model that demonstrates high proficiency in specific domains like coding and mathematics"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenAI GPT 3.5 Turbo"}),(0,s.jsx)(d.td,{children:"The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug that caused a text encoding issue for non-English language function calls"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenAI GPT 3.5 Turbo 16k 0613"}),(0,s.jsx)(d.td,{children:"A Snapshot model of gpt-3.5-16k-turbo from June 13th 2023"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenAI GPT 4"}),(0,s.jsx)(d.td,{children:"The latest GPT-4 model intended to reduce cases of \u201claziness\u201d where the model doesn't complete a task"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"TinyLlama Chat 1.1B Q4"}),(0,s.jsx)(d.td,{children:"A tiny model with only 1.1B. It's a good model for less powerful computers"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Deepseek Coder 1.3B Q8"}),(0,s.jsx)(d.td,{children:"A model that excelled in project-level code completion with advanced capabilities across multiple programming languages"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Phi-2 3B Q8"}),(0,s.jsx)(d.td,{children:"a 2.7B model, excelling in common sense and logical reasoning benchmarks, trained with synthetic texts and filtered websites"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Llama 2 Chat 7B Q4"}),(0,s.jsx)(d.td,{children:"A model that is specifically designed for a comprehensive understanding through training on extensive internet data"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"CodeNinja 7B Q4"}),(0,s.jsx)(d.td,{children:"A model that is good for coding tasks and can handle various languages, including Python, C, C++, Rust, Java, JavaScript, and more"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Noromaid 7B Q5"}),(0,s.jsx)(d.td,{children:"A model designed for role-playing with human-like behavior."})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Starling alpha 7B Q4"}),(0,s.jsx)(d.td,{children:"An upgrade of Openchat 3.5 using RLAIF, is good at various benchmarks, especially with GPT-4 judging its performance"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Yarn Mistral 7B Q4"}),(0,s.jsx)(d.td,{children:"A language model for long context and supports a 128k token context window"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"LlaVa 1.5 7B Q5 K"}),(0,s.jsx)(d.td,{children:"A model can bring vision understanding to Jan"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"BakLlava 1"}),(0,s.jsx)(d.td,{children:"A model can bring vision understanding to Jan"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Solar Slerp 10.7B Q4"}),(0,s.jsx)(d.td,{children:"A model that uses the Slerp merge method from SOLAR Instruct and Pandora-v1"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"LlaVa 1.5 13B Q5 K"}),(0,s.jsx)(d.td,{children:"A model can bring vision understanding to Jan"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Deepseek Coder 33B Q5"}),(0,s.jsx)(d.td,{children:"A model that excelled in project-level code completion with advanced capabilities across multiple programming languages"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Phind 34B Q5"}),(0,s.jsx)(d.td,{children:"A multi-lingual model that is fine-tuned on 1.5B tokens of high-quality programming data, excels in various programming languages, and is designed to be steerable and user-friendly"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Yi 34B Q5"}),(0,s.jsx)(d.td,{children:"A specialized chat model is known for its diverse and creative responses and excels across various NLP tasks and benchmarks"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Capybara 200k 34B Q5"}),(0,s.jsx)(d.td,{children:"A long context length model that supports 200K tokens"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Dolphin 8x7B Q4"}),(0,s.jsx)(d.td,{children:"An uncensored model built on Mixtral-8x7b and it is good at programming tasks"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Mixtral 8x7B Instruct Q4"}),(0,s.jsx)(d.td,{children:"A pre-trained generative Sparse Mixture of Experts, which outperforms 70B models on most benchmarks"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Tulu 2 70B Q4"}),(0,s.jsx)(d.td,{children:"A strong model alternative to Llama 2 70b Chat to act as helpful assistants"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Llama 2 Chat 70B Q4"}),(0,s.jsx)(d.td,{children:"A model that is specifically designed for a comprehensive understanding through training on extensive internet data"})]})]})]}),"\n",(0,s.jsx)(d.admonition,{type:"note",children:(0,s.jsxs)(d.p,{children:["OpenAI GPT models require a subscription to use them further. To learn more, ",(0,s.jsx)(d.a,{href:"https://openai.com/pricing",children:"click here"}),"."]})}),"\n",(0,s.jsx)(d.h2,{id:"model-details",children:"Model details"}),"\n",(0,s.jsxs)(d.table,{children:[(0,s.jsx)(d.thead,{children:(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.th,{children:"Model"}),(0,s.jsx)(d.th,{children:"Author"}),(0,s.jsx)(d.th,{children:"Model ID"}),(0,s.jsx)(d.th,{children:"Format"}),(0,s.jsx)(d.th,{children:"Size"})]})}),(0,s.jsxs)(d.tbody,{children:[(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Mistral Instruct 7B Q4"}),(0,s.jsx)(d.td,{children:"MistralAI, The Bloke"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"mistral-ins-7b-q4"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenHermes Neural 7B Q4"}),(0,s.jsx)(d.td,{children:"Intel, Jan"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"openhermes-neural-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Stealth 7B Q4"}),(0,s.jsx)(d.td,{children:"Jan"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"stealth-v1.2-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Trinity-v1.2 7B Q4"}),(0,s.jsx)(d.td,{children:"Jan"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"trinity-v1.2-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Openchat-3.5 7B Q4"}),(0,s.jsx)(d.td,{children:"Openchat"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"openchat-3.5-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Wizard Coder Python 13B Q5"}),(0,s.jsx)(d.td,{children:"WizardLM, The Bloke"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"wizardcoder-13b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"7.33GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenAI GPT 3.5 Turbo"}),(0,s.jsx)(d.td,{children:"OpenAI"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"gpt-3.5-turbo"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"-"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenAI GPT 3.5 Turbo 16k 0613"}),(0,s.jsx)(d.td,{children:"OpenAI"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"gpt-3.5-turbo-16k-0613"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"-"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"OpenAI GPT 4"}),(0,s.jsx)(d.td,{children:"OpenAI"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"gpt-4"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"-"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"TinyLlama Chat 1.1B Q4"}),(0,s.jsx)(d.td,{children:"TinyLlama"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"tinyllama-1.1b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"638.01MB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Deepseek Coder 1.3B Q8"}),(0,s.jsx)(d.td,{children:"Deepseek, The Bloke"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"deepseek-coder-1.3b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"1.33GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Phi-2 3B Q8"}),(0,s.jsx)(d.td,{children:"Microsoft"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"phi-2-3b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"2.76GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Llama 2 Chat 7B Q4"}),(0,s.jsx)(d.td,{children:"MetaAI, The Bloke"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"llama2-chat-7b-q4"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"3.80GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"CodeNinja 7B Q4"}),(0,s.jsx)(d.td,{children:"Beowolx"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"codeninja-1.0-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Noromaid 7B Q5"}),(0,s.jsx)(d.td,{children:"NeverSleep"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"noromaid-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Starling alpha 7B Q4"}),(0,s.jsx)(d.td,{children:"Berkeley-nest, The Bloke"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"starling-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"Yarn Mistral 7B Q4"}),(0,s.jsx)(d.td,{children:"NousResearch, The Bloke"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"yarn-mistral-7b"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"4.07GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"LlaVa 1.5 7B Q5 K"}),(0,s.jsx)(d.td,{children:"Mys"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"llava-1.5-7b-q5"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"5.03GB"})]}),(0,s.jsxs)(d.tr,{children:[(0,s.jsx)(d.td,{children:"BakLlava 1"}),(0,s.jsx)(d.td,{children:"Mys"}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.code,{children:"bakllava-1"})}),(0,s.jsx)(d.td,{children:(0,s.jsx)(d.strong,{children:"GGUF"})}),(0,s.jsx)(d.td,{children:"5.36GB"})]})]})]})]})}function a(e={}){const{wrapper:d}={...(0,r.a)(),...e.components};return d?(0,s.jsx)(d,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},11151:(e,d,n)=>{n.d(d,{Z:()=>l,a:()=>i});var s=n(67294);const r={},t=s.createContext(r);function i(e){const d=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(d):{...d,...e}}),[d,e])}function l(e){let d;return d=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(t.Provider,{value:d},e.children)}}}]);