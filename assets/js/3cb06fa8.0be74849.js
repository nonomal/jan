"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5537],{34694:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>d});var a=t(85893),l=t(11151);const o={title:"Ollama",sidebar_position:9,description:"A step-by-step guide on how to integrate Jan with Ollama.",keywords:["Jan AI","Jan","ChatGPT alternative","local AI","private AI","conversational AI","no-subscription fee","large language model","Ollama integration"]},i=void 0,r={id:"guides/integration/ollama",title:"Ollama",description:"A step-by-step guide on how to integrate Jan with Ollama.",source:"@site/docs/guides/integration/ollama.mdx",sourceDirName:"guides/integration",slug:"/guides/integration/ollama",permalink:"/guides/integration/ollama",draft:!1,unlisted:!1,editUrl:"https://github.com/janhq/jan/tree/dev/docs/docs/guides/integration/ollama.mdx",tags:[],version:"current",lastUpdatedBy:"Daniel",lastUpdatedAt:1710427956,formattedLastUpdatedAt:"Mar 14, 2024",sidebarPosition:9,frontMatter:{title:"Ollama",sidebar_position:9,description:"A step-by-step guide on how to integrate Jan with Ollama.",keywords:["Jan AI","Jan","ChatGPT alternative","local AI","private AI","conversational AI","no-subscription fee","large language model","Ollama integration"]},sidebar:"guidesSidebar",previous:{title:"Mistral AI",permalink:"/guides/integration/mistral"},next:{title:"Open Interpreter",permalink:"/guides/integration/openinterpreter"}},s={},d=[{value:"How to Integrate Ollama with Jan",id:"how-to-integrate-ollama-with-jan",level:2},{value:"Step 1: Start the Ollama Server",id:"step-1-start-the-ollama-server",level:3},{value:"Step 2: Model Configuration",id:"step-2-model-configuration",level:3},{value:"Step 3: Start the Model",id:"step-3-start-the-model",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.a)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"how-to-integrate-ollama-with-jan",children:"How to Integrate Ollama with Jan"}),"\n",(0,a.jsx)(n.p,{children:"Ollama provides you with largen language that you can run locally. There are two methods to integrate Ollama with Jan:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Integrate Ollama server with Jan."}),"\n",(0,a.jsx)(n.li,{children:"Migrate the downloaded model from Ollama to Jan."}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"To integrate Ollama with Jan, follow the steps below:"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["In this tutorial, we'll show how to integrate Ollama with Jan using the first method. We will use the ",(0,a.jsx)(n.a,{href:"https://ollama.com/library/llama2",children:"llama2"})," model as an example."]})}),"\n",(0,a.jsx)(n.h3,{id:"step-1-start-the-ollama-server",children:"Step 1: Start the Ollama Server"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Choose your model from the ",(0,a.jsx)(n.a,{href:"https://ollama.com/library",children:"Ollama library"}),"."]}),"\n",(0,a.jsx)(n.li,{children:"Run your model with this command:"}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-sh",children:"ollama run <model-name>\n"})}),"\n",(0,a.jsxs)(n.ol,{start:"3",children:["\n",(0,a.jsxs)(n.li,{children:["According to the ",(0,a.jsx)(n.a,{href:"https://github.com/ollama/ollama/blob/main/docs/openai.md",children:"Ollama documentation on OpenAI compatibility"}),", you can connect to the Ollama server using the web address ",(0,a.jsx)(n.code,{children:"http://localhost:11434/v1/chat/completions"}),". To do this, change the ",(0,a.jsx)(n.code,{children:"openai.json"})," file in the ",(0,a.jsx)(n.code,{children:"~/jan/engines"})," folder to add the Ollama server's full web address:"]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/engines/openai.json"',children:'{\n  "full_url": "http://localhost:11434/v1/chat/completions"\n}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-2-model-configuration",children:"Step 2: Model Configuration"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Navigate to the ",(0,a.jsx)(n.code,{children:"~/jan/models"})," folder."]}),"\n",(0,a.jsxs)(n.li,{children:["Create a folder named ",(0,a.jsx)(n.code,{children:"(ollam-modelname)"}),", for example, ",(0,a.jsx)(n.code,{children:"lmstudio-phi-2"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Create a ",(0,a.jsx)(n.code,{children:"model.json"})," file inside the folder including the following configurations:"]}),"\n"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"id"})," property to the model name as Ollama model name."]}),"\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"format"})," property to ",(0,a.jsx)(n.code,{children:"api"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"engine"})," property to ",(0,a.jsx)(n.code,{children:"openai"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Set the ",(0,a.jsx)(n.code,{children:"state"})," property to ",(0,a.jsx)(n.code,{children:"ready"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/models/llama2/model.json"',children:'{\n  "sources": [\n    {\n      "filename": "llama2",\n      "url": "https://ollama.com/library/llama2"\n    }\n  ],\n  "id": "llama2",\n  "object": "model",\n  "name": "Ollama - Llama2",\n  "version": "1.0",\n  "description": "Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.",\n  "format": "api",\n  "settings": {},\n  "parameters": {},\n  "metadata": {\n    "author": "Meta",\n    "tags": ["General", "Big Context Length"]\n  },\n  "engine": "openai"\n}\n'})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["For more details regarding the ",(0,a.jsx)(n.code,{children:"model.json"})," settings and parameters fields,  please see ",(0,a.jsx)(n.a,{href:"/guides/models/integrate-remote#modeljson",children:"here"}),"."]})}),"\n",(0,a.jsx)(n.h3,{id:"step-3-start-the-model",children:"Step 3: Start the Model"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Restart Jan and navigate to the ",(0,a.jsx)(n.strong,{children:"Hub"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["Locate your model and click the ",(0,a.jsx)(n.strong,{children:"Use"})," button."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.a)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>i});var a=t(67294);const l={},o=a.createContext(l);function i(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);